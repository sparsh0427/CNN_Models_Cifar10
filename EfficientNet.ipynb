{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled26.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xAuvGsCESha"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD,Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-UcPWivEC60"
      },
      "source": [
        "(x_train1, y_train), (x_test1, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train1 = x_train1.reshape(x_train1.shape[0], 28, 28,1)\n",
        "x_test1 = x_test1.reshape(x_test1.shape[0], 28, 28,1)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62JgLkleHGRH"
      },
      "source": [
        "x_train = np.empty((60000,32,32,3), dtype=float, order='C')\n",
        "x_test = np.empty((10000,32,32,3), dtype=float, order='C')\n",
        "# y_train = np.empty((60000,28,28,3), dtype=float, order='C')\n",
        "# y_test = np.empty((10000,28,28,3), dtype=float, order='C')"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoOujHCrH5Sm",
        "outputId": "c65b1612-32c6-4471-feb5-dc7a8a05944b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj6gD8UuGbpc"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkb7oJ6tLgnm",
        "outputId": "b74a826f-45da-4e59-cc76-166ce4f28cfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train1[0].shape"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpf_ncYsMGEX"
      },
      "source": [
        ""
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYSEenN6Gm3G"
      },
      "source": [
        "for i in range(60000):\n",
        "  x_train[i] = cv2.cvtColor(x_train1[i],cv2.COLOR_GRAY2RGB).resize((32,32,3))\n",
        "  # x_train[i] = cv2.resize(x_train[i], (32, 32,3))\n",
        "\n",
        "for i in range(10000):\n",
        "  x_test[i] = cv2.cvtColor(x_test1[i],cv2.COLOR_GRAY2RGB).resize((32,32,3))\n",
        "  # x_test[i] = cv2.resize(x_test1[i], (32, 32))"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzeElTpAGBt-",
        "outputId": "5208d9bb-8b37-45a8-d6b1-d32521a52bd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_EoO-jCEsyw",
        "outputId": "4547dc90-572d-45e6-a450-16d1868da982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install Keras-Applications"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Keras-Applications in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras-Applications) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras-Applications) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras-Applications) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0t0BT-YGAhY",
        "outputId": "3aa5600e-10c0-4f25-a661-6f9add42d796",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gj07_ZREk7f"
      },
      "source": [
        "from keras_efficientnets import EfficientNetB5"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1PCk8DIEojy",
        "outputId": "2f56e707-6577-4adf-d990-4eff820652c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n",
        "\n",
        "#Dimension of the CIFAR10 dataset\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))\n"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((42000, 32, 32, 3), (42000,))\n",
            "((18000, 32, 32, 3), (18000,))\n",
            "((10000, 32, 32, 3), (10000,))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCzCJeAaE2Am",
        "outputId": "3c17d8f1-c057-4807-87e7-bf27ac4e7c81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.utils.multiclass import unique_labels\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)\n",
        "\n",
        "#Verifying the dimension after one hot encoding\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))\n"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((42000, 32, 32, 3), (42000, 10))\n",
            "((18000, 32, 32, 3), (18000, 10))\n",
            "((10000, 32, 32, 3), (10000, 10))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvqBZYszFYIg"
      },
      "source": [
        ""
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ_ueoedFaev"
      },
      "source": [
        ""
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-ZGiFr3FdaL"
      },
      "source": [
        "from keras_efficientnets import EfficientNetB5"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOAKUAhvFkq4",
        "outputId": "ab18b065-5f3b-44c1-fcfe-c046084c3c36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_model = EfficientNetB5(include_top=False, weights=\"imagenet\", input_shape=(32,32,3),classes=y_train.shape[1])\n",
        "\n",
        "#Adding the final layers to the above base models where the actual classification is done in the dense layers\n",
        "\n",
        "model= Sequential()\n",
        "model.add(base_model) \n",
        "model.add(Flatten()) \n",
        "\n",
        "#Model summary\n",
        "# model.summary()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "functional_3 (Functional)    (None, 1, 1, 2048)        28513520  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "=================================================================\n",
            "Total params: 28,513,520\n",
            "Trainable params: 28,340,784\n",
            "Non-trainable params: 172,736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q6e00DhFqS_",
        "outputId": "034867d3-1be9-4f99-8a43-5f629fb50abd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "\n",
        "model.add(Dense(512,activation=('relu'))) \n",
        "model.add(Dense(256,activation=('relu'))) \n",
        "#model.add(Dropout(.3))\n",
        "model.add(Dense(128,activation=('relu')))\n",
        "#model.add(Dropout(.2))\n",
        "model.add(Dense(10,activation=('softmax'))) \n",
        "\n",
        "#Checking the final model summary\n",
        "model.summary()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "functional_3 (Functional)    (None, 1, 1, 2048)        28513520  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 31,302,010\n",
            "Trainable params: 31,129,274\n",
            "Non-trainable params: 172,736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K650IAONQTY"
      },
      "source": [
        "batch_size= 100\n",
        "epochs=1\n",
        "learn_rate=.001"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfxhUCf6NSFn"
      },
      "source": [
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN9YX8mlNVSJ",
        "outputId": "69175ea8-235c-41ba-f4fb-8b9a1d57968d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit_generator(train_generator.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size = batch_size), validation_steps = 250,  callbacks = [lrr], verbose = 1)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "420/420 [==============================] - ETA: 0s - loss: 2.3021 - accuracy: 0.1124WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 250 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "420/420 [==============================] - 55s 131ms/step - loss: 2.3021 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4eb790de48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnk_DP-yNXpr",
        "outputId": "255426b4-2c30-44c3-a6b6-1512f8d2fc5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scores = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 7s 22ms/step - loss: 2.3017 - accuracy: 0.1135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqw40-muN7F0",
        "outputId": "f7d0355b-e6a5-4c11-8eaa-6e5d2ce21d66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scores[0]"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.3017184734344482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2rd1jOIO-oj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S75RqUuKO-wz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLK21TKUN-pg",
        "outputId": "f2b53f07-db49-46af-f623-451a9866119b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Untitled23.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1KJrUlq1GepTt_dWJErbSBM7j0rLsp5Yo\n",
        "\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Untitled20.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/10IhJDTxUdN5ftPedFOvP7PYqXcYPLCJr\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "from keras_efficientnets import EfficientNetB5\n",
        "import keras\n",
        "import tensorflow as tf \n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Training parameters\n",
        "def model(parameter,x_train,y_train,x_test,y_test):\n",
        "  base_model = EfficientNetB5(include_top=False, weights=\"imagenet\", input_shape=(32,32,3),classes=y_train.shape[1])\n",
        "\n",
        "  #Adding the final layers to the above base models where the actual classification is done in the dense layers\n",
        "  model= Sequential()\n",
        "  model.add(base_model) \n",
        "  model.add(Flatten()) \n",
        "\n",
        "  model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "\n",
        "  model.add(Dense(512,activation=('relu'))) \n",
        "  model.add(Dense(256,activation=('relu'))) \n",
        "  #model.add(Dropout(.3))\n",
        "  model.add(Dense(128,activation=('relu')))\n",
        "  #model.add(Dropout(.2))\n",
        "  model.add(Dense(10,activation=('softmax'))) \n",
        "\n",
        "  #Checking the final model summary\n",
        "  model.summary()\n",
        "  batch_size = math.floor(parameter[1])\n",
        "  epochs = math.floor(parameter[2])\n",
        "  learn_rate = parameter[0]\n",
        "\n",
        "  sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "\n",
        "  model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "  model.fit_generator(train_generator.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size = batch_size), validation_steps = 250,verbose = 1)\n",
        "  scores = model.evaluate(x_test, y_test)\n",
        "  return scores[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "#------------------------------------------------------------------------------\n",
        "# TO CUSTOMIZE THIS PSO CODE TO SOLVE UNCONSTRAINED OPTIMIZATION PROBLEMS, CHANGE THE PARAMETERS IN THIS SECTION ONLY:\n",
        "# THE FOLLOWING PARAMETERS MUST BE CHANGED.\n",
        "def objective_function(x):\n",
        "    y = 3*(1-x[0])**2*math.exp(-x[0]**2 - (x[1]+1)**2) - 10*(x[0]/5 - x[0]**3 - x[1]**5)*math.exp(-x[0]**2 - x[1]**2) -1/3*math.exp(-(x[0]+1)**2 - x[1]**2);\n",
        "    return y\n",
        " \n",
        "bounds=[(0.0001,0.1),(16,256),(1,100)]   # upper and lower bounds of variables #learning rate #batch size #epochs #growth rate\n",
        "\n",
        "nv = 3                   # number of variables\n",
        "mm = -1                   # if minimization problem, mm = -1; if maximization problem, mm = 1\n",
        "(x_train1, y_train), (x_test1, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train1 = x_train1.reshape(x_train1.shape[0], 28, 28,1)\n",
        "x_test1 = x_test1.reshape(x_test1.shape[0], 28, 28,1)\n",
        "x_train = np.empty((60000,32,32,3), dtype=float, order='C')\n",
        "x_test = np.empty((10000,32,32,3), dtype=float, order='C')\n",
        "for i in range(60000):\n",
        "  x_train[i] = cv2.cvtColor(x_train1[i],cv2.COLOR_GRAY2RGB).resize((32,32,3))\n",
        "  # x_train[i] = cv2.resize(x_train[i], (32, 32,3))\n",
        "\n",
        "for i in range(10000):\n",
        "  x_test[i] = cv2.cvtColor(x_test1[i],cv2.COLOR_GRAY2RGB).resize((32,32,3))\n",
        "\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)\n",
        "# THE FOLLOWING PARAMETERS ARE OPTINAL.\n",
        "particle_size=1         # number of particles\n",
        "iterations=1         # max number of iterations\n",
        "w=0.85                    # inertia constant\n",
        "c1=1                    # cognative constant\n",
        "c2=2                     # social constant\n",
        "# END OF THE CUSTOMIZATION SECTION\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "class Particle:\n",
        "    def __init__(self,bounds):\n",
        "        self.particle_position=[]                     # particle position\n",
        "        self.particle_velocity=[]                     # particle velocity\n",
        "        self.local_best_particle_position=[]          # best position of the particle\n",
        "        self.fitness_local_best_particle_position= initial_fitness  # initial objective function value of the best particle position\n",
        "        self.fitness_particle_position=initial_fitness             # objective function value of the particle position\n",
        " \n",
        "        for i in range(nv):\n",
        "            self.particle_position.append(random.uniform(bounds[i][0],bounds[i][1])) # generate random initial position\n",
        "            self.particle_velocity.append(random.uniform(-1,1)) # generate random initial velocity\n",
        " \n",
        "    def evaluate(self,objective_function):\n",
        "        self.fitness_particle_position=model(self.particle_position,x_train,y_train,x_test,y_test)\n",
        "        if mm == -1:\n",
        "            if self.fitness_particle_position < self.fitness_local_best_particle_position:\n",
        "                self.local_best_particle_position=self.particle_position                  # update the local best\n",
        "                self.fitness_local_best_particle_position=self.fitness_particle_position  # update the fitness of the local best\n",
        "        if mm == 1:\n",
        "            if self.fitness_particle_position > self.fitness_local_best_particle_position:\n",
        "                self.local_best_particle_position=self.particle_position                  # update the local best\n",
        "                self.fitness_local_best_particle_position=self.fitness_particle_position  # update the fitness of the local best\n",
        " \n",
        "    def update_velocity(self,global_best_particle_position):\n",
        "        for i in range(nv):\n",
        "            r1=random.random()\n",
        "            r2=random.random()\n",
        " \n",
        "            cognitive_velocity = c1*r1*(self.local_best_particle_position[i] - self.particle_position[i])\n",
        "            social_velocity = c2*r2*(global_best_particle_position[i] - self.particle_position[i])\n",
        "            self.particle_velocity[i] = w*self.particle_velocity[i]+ cognitive_velocity + social_velocity\n",
        " \n",
        "    def update_position(self,bounds):\n",
        "        for i in range(nv):\n",
        "            self.particle_position[i]=self.particle_position[i]+self.particle_velocity[i]\n",
        " \n",
        "            # check and repair to satisfy the upper bounds\n",
        "            if self.particle_position[i]>bounds[i][1]:\n",
        "                self.particle_position[i]=bounds[i][1]\n",
        "            # check and repair to satisfy the lower bounds\n",
        "            if self.particle_position[i] < bounds[i][0]:\n",
        "                self.particle_position[i]=bounds[i][0]\n",
        "\n",
        "class PSO():\n",
        "    def __init__(self,objective_function,bounds,particle_size,iterations):\n",
        " \n",
        "        fitness_global_best_particle_position=initial_fitness\n",
        "        global_best_particle_position=[]\n",
        " \n",
        "        swarm_particle=[]\n",
        "        for i in range(particle_size):\n",
        "            swarm_particle.append(Particle(bounds))\n",
        "        A=[]\n",
        "         \n",
        "        for i in range(iterations):\n",
        "            print(\"iterations = \",i)\n",
        "            for j in range(particle_size):\n",
        "                swarm_particle[j].evaluate(objective_function)\n",
        " \n",
        "                if mm ==-1:\n",
        "                    if swarm_particle[j].fitness_particle_position < fitness_global_best_particle_position:\n",
        "                        global_best_particle_position = list(swarm_particle[j].particle_position)\n",
        "                        fitness_global_best_particle_position = float(swarm_particle[j].fitness_particle_position)\n",
        "                if mm ==1:\n",
        "                    if swarm_particle[j].fitness_particle_position > fitness_global_best_particle_position:\n",
        "                        global_best_particle_position = list(swarm_particle[j].particle_position)\n",
        "                        fitness_global_best_particle_position = float(swarm_particle[j].fitness_particle_position)\n",
        "            for j in range(particle_size):\n",
        "                swarm_particle[j].update_velocity(global_best_particle_position)\n",
        "                swarm_particle[j].update_position(bounds)\n",
        "                 \n",
        "            A.append(fitness_global_best_particle_position) # record the best fitness\n",
        "             \n",
        "             \n",
        "        print('Optimal solution:', global_best_particle_position)\n",
        "        print('Objective function value:', fitness_global_best_particle_position)\n",
        "        print('Evolutionary process of the objective function value:')\n",
        "        plt.plot(A)\n",
        "#------------------------------------------------------------------------------\n",
        "if mm == -1:\n",
        "    initial_fitness = float(\"inf\") # for minimization problem\n",
        "if mm == 1:\n",
        "    initial_fitness = -float(\"inf\") # for maximization problem\n",
        "#------------------------------------------------------------------------------   \n",
        "# Main PSO         \n",
        "# PSO(objective_function,bounds,particle_size,iterations)\n",
        "\n",
        "PSO(model,bounds,particle_size,iterations)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iterations =  0\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "functional_5 (Functional)    (None, 1, 1, 2048)        28513520  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 31,302,010\n",
            "Trainable params: 31,129,274\n",
            "Non-trainable params: 172,736\n",
            "_________________________________________________________________\n",
            "Epoch 1/23\n",
            "206/206 [==============================] - ETA: 0s - loss: 2.3022 - accuracy: 0.1111"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6xUYON6QmLb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}